# MeuPaoZin API

API para gerenciamento de pedidos de pÃ£es com integraÃ§Ã£o Kafka para processamento de eventos em tempo real.

## ğŸš€ Funcionalidades

- **GestÃ£o de Clientes**: CRUD completo de clientes
- **GestÃ£o de Tipos de PÃ£o**: CRUD de tipos de pÃ£o com preÃ§os
- **GestÃ£o de Status de Pedidos**: Estados como Pendente, Em Preparo, Pronto, etc.
- **GestÃ£o de Pedidos**: CRUD de pedidos com relacionamentos
- **IntegraÃ§Ã£o Kafka**: Processamento assÃ­ncrono de eventos
- **NotificaÃ§Ãµes em Tempo Real**: Eventos para dashboards e sistemas externos
- **Analytics**: Coleta de dados para relatÃ³rios e anÃ¡lises

## ğŸ—ï¸ Arquitetura

### Componentes

- **NestJS**: Framework backend
- **PostgreSQL**: Banco de dados principal
- **Kafka**: Sistema de mensageria para eventos
- **Zookeeper**: CoordenaÃ§Ã£o do Kafka
- **Kafka UI**: Interface web para visualizar tÃ³picos

### Fluxo de Eventos

```
Cliente faz pedido â†’ API cria pedido â†’ Kafka envia evento â†’ 
Sistemas processam evento â†’ NotificaÃ§Ãµes enviadas â†’ 
Dashboard atualizado â†’ Analytics processados
```

## ğŸ› ï¸ Tecnologias

- **Backend**: NestJS, TypeScript
- **Banco de Dados**: PostgreSQL, TypeORM
- **Mensageria**: Apache Kafka
- **DocumentaÃ§Ã£o**: Swagger/OpenAPI
- **ContainerizaÃ§Ã£o**: Docker, Docker Compose

## ğŸ“¦ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Docker e Docker Compose
- Node.js 18+
- npm ou yarn

### ConfiguraÃ§Ã£o Inicial

#### OpÃ§Ã£o 1: Setup AutomÃ¡tico (Recomendado)

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd meu-paozin-api

# Execute o script de configuraÃ§Ã£o
./scripts/setup-env.sh

# Instale as dependÃªncias
npm install

# Inicie o sistema completo
npm run setup:complete
```

#### OpÃ§Ã£o 2: Setup Manual

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd meu-paozin-api

# Copie o arquivo de configuraÃ§Ã£o
cp env-complete.txt .env

# Edite as variÃ¡veis conforme necessÃ¡rio
nano .env

# Instale as dependÃªncias
npm install

# Inicie o sistema completo
npm run setup:complete
```

### VariÃ¡veis de Ambiente

O sistema utiliza vÃ¡rias variÃ¡veis de ambiente para configuraÃ§Ã£o. Veja a documentaÃ§Ã£o completa em [docs/ENV-SETUP.md](./docs/ENV-SETUP.md).

#### VariÃ¡veis ObrigatÃ³rias

```bash
# AplicaÃ§Ã£o
NODE_ENV=development
PORT=3000

# Banco de Dados
DB_HOST=localhost
DB_PORT=5432
DB_USERNAME=postgres
DB_PASSWORD=password
DB_NAME=pedidos_db

# Kafka
KAFKA_CLIENT_ID=meu-paozin-api
KAFKA_BROKERS=localhost:9092
KAFKA_GROUP_ID=meu-paozin-group
KAFKA_CONSUMER_GROUP_ID=meu-paozin-consumer-group
```

### Setup Completo

O comando `npm run setup:complete` irÃ¡:
1. Iniciar todos os containers (PostgreSQL + Kafka + Zookeeper)
2. Aguardar o Kafka estar pronto
3. Criar os tÃ³picos necessÃ¡rios
4. Inserir dados de exemplo

### Setup Manual

```bash
# 1. Iniciar containers
npm run docker:up

# 2. Aguardar Kafka estar pronto (30s)
sleep 30

# 3. Criar tÃ³picos Kafka
npm run kafka:init-topics

# 4. Inserir dados de exemplo
npm run docker:seed
```

## ğŸš€ Como Usar

### Acessos

- **API**: http://localhost:3000
- **Swagger**: http://localhost:3000/api
- **Kafka UI**: http://localhost:8080
- **Observabilidade**: http://localhost:3000/api/observability/health

### Comandos Ãšteis

```bash
# Ver status dos containers
npm run docker:status

# Ver logs da aplicaÃ§Ã£o
npm run docker:logs

# Ver logs do Kafka
npm run kafka:logs

# Abrir Kafka UI
npm run kafka:ui

# Testar eventos Kafka
npm run kafka:test

# Gerenciar Datadog
npm run datadog:up
npm run datadog:down
npm run datadog:logs
npm run datadog:status

# Parar todos os containers
npm run docker:down

# Limpar tudo (volumes incluÃ­dos)
npm run docker:clean
```

## ğŸ“Š Eventos Kafka

### TÃ³picos Implementados

| TÃ³pico | DescriÃ§Ã£o | Eventos |
|--------|-----------|---------|
| `pedidos.created` | Pedidos criados | PEDIDO_CREATED |
| `pedidos.updated` | Pedidos atualizados | PEDIDO_UPDATED |
| `pedidos.status-changed` | MudanÃ§as de status | PEDIDO_STATUS_CHANGED |
| `pedidos.cancelled` | Pedidos cancelados | PEDIDO_CANCELLED |
| `clientes.created` | Clientes criados | CLIENTE_CREATED |
| `tipos-pao.updated` | Tipos de pÃ£o atualizados | TIPO_PAO_UPDATED |
| `analytics.events` | Eventos de analytics | VÃ¡rios tipos |

### Exemplo de Evento

```json
{
  "eventType": "PEDIDO_CREATED",
  "pedidoId": 1,
  "clienteId": 1,
  "tipoPaoId": 1,
  "quantidade": 5,
  "precoTotal": 17.50,
  "statusId": 1,
  "timestamp": "2024-01-15T10:30:00.000Z"
}
```

## ğŸ”§ Desenvolvimento

### Estrutura do Projeto

```
src/
â”œâ”€â”€ kafka/                 # MÃ³dulo Kafka
â”‚   â”œâ”€â”€ kafka.module.ts
â”‚   â”œâ”€â”€ kafka.service.ts
â”‚   â”œâ”€â”€ kafka-producer.service.ts
â”‚   â””â”€â”€ kafka-consumer.service.ts
â”œâ”€â”€ pedidos/              # MÃ³dulo de Pedidos
â”œâ”€â”€ clientes/             # MÃ³dulo de Clientes
â”œâ”€â”€ tipos-pao/            # MÃ³dulo de Tipos de PÃ£o
â””â”€â”€ status-pedido/        # MÃ³dulo de Status
```

### Adicionando Novos Eventos

1. **Criar mÃ©todo no KafkaProducerService**:
```typescript
async sendNovoEvento(data: any): Promise<void> {
  await this.sendEvent({
    topic: 'novo.topic',
    key: `novo-${data.id}`,
    value: {
      eventType: 'NOVO_EVENTO',
      ...data,
      timestamp: new Date().toISOString(),
    },
  });
}
```

2. **Criar handler no KafkaConsumerService**:
```typescript
this.registerHandler({
  topic: 'novo.topic',
  handler: async (message) => {
    console.log('Novo evento processado:', message);
    // Implementar lÃ³gica
  },
});
```

3. **Chamar no serviÃ§o**:
```typescript
await this.kafkaProducer.sendNovoEvento(data);
```

## ğŸ“ˆ Monitoramento

### Logs

O sistema registra logs detalhados:
- âœ… ConexÃµes bem-sucedidas
- âŒ Erros de conexÃ£o
- ğŸ“¤ Eventos enviados
- ğŸ“¨ Mensagens recebidas

### Kafka UI

Acesse http://localhost:8080 para:
- Visualizar tÃ³picos
- Ver mensagens em tempo real
- Monitorar configuraÃ§Ãµes

## ğŸ§ª Testes

### Teste de Eventos Kafka

```bash
npm run kafka:test
```

Este script irÃ¡:
1. Criar um cliente
2. Criar um pedido
3. Atualizar status do pedido
4. Atualizar tipo de pÃ£o
5. Remover pedido

### Verificando Eventos

1. Execute o teste: `npm run kafka:test`
2. Abra o Kafka UI: `npm run kafka:ui`
3. Verifique os tÃ³picos e mensagens

## ğŸ” Troubleshooting

### Problemas Comuns

1. **Kafka nÃ£o conecta**
   ```bash
   npm run kafka:logs
   # Verificar se o container estÃ¡ rodando
   ```

2. **TÃ³picos nÃ£o criados**
   ```bash
   npm run kafka:init-topics
   # Aguardar Kafka estar pronto
   ```

3. **AplicaÃ§Ã£o nÃ£o inicia**
   ```bash
   npm run docker:logs
   # Verificar logs da aplicaÃ§Ã£o
   ```

### Debug

```bash
# Ver status dos containers
docker-compose ps

# Ver logs especÃ­ficos
docker-compose logs -f app
docker-compose logs -f kafka

# Reiniciar tudo
npm run docker:restart
```

## ğŸ“š DocumentaÃ§Ã£o

- [ConfiguraÃ§Ã£o de VariÃ¡veis de Ambiente](./docs/ENV-SETUP.md)
- [ImplementaÃ§Ã£o do Datadog](./docs/DATADOG-IMPLEMENTATION.md)
- [IntegraÃ§Ã£o Kafka](./docs/KAFKA-INTEGRATION.md)
- [AnÃ¡lise de Bibliotecas](./docs/libs/README.md)
- [Swagger API](./docs/SWAGGER.md)

## ğŸ”„ CI/CD (GitHub Actions)

O projeto inclui um pipeline completo de CI/CD configurado no GitHub Actions:

### Workflow IncluÃ­do

- **Testes**: UnitÃ¡rios e E2E com PostgreSQL e Kafka
- **Build**: CompilaÃ§Ã£o e validaÃ§Ã£o da aplicaÃ§Ã£o
- **Docker**: Build e push de imagens
- **SeguranÃ§a**: AnÃ¡lise com Snyk e npm audit
- **Deploy**: Staging e ProduÃ§Ã£o

### Secrets NecessÃ¡rios

Configure os seguintes secrets no seu repositÃ³rio:

- `DOCKER_USERNAME`: UsuÃ¡rio do Docker Hub
- `DOCKER_PASSWORD`: Senha do Docker Hub
- `SNYK_TOKEN`: Token do Snyk (opcional)

### ExecuÃ§Ã£o

O pipeline Ã© executado automaticamente em:
- Push para `main` e `develop`
- Pull Requests para `main` e `develop`

## ğŸš€ PrÃ³ximos Passos

### ImplementaÃ§Ãµes Futuras

- [ ] Dead Letter Queue para mensagens falhadas
- [ ] Retry Policy para mensagens
- [ ] Schema Registry para validaÃ§Ã£o
- [ ] Streaming Analytics
- [ ] IntegraÃ§Ã£o com sistemas externos

### Melhorias

- [ ] CompressÃ£o de mensagens
- [ ] Partitioning avanÃ§ado
- [ ] ReplicaÃ§Ã£o para alta disponibilidade
- [ ] SeguranÃ§a (SASL/SSL)

## ğŸ“„ LicenÃ§a

Este projeto Ã© para fins educacionais.

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

---

**Desenvolvido para estudo de integraÃ§Ã£o Kafka com NestJS** ğŸš€
